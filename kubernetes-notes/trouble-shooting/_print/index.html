<!doctype html>
<html lang="zh-cn" class="no-js">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="generator" content="Hugo 0.101.0" />
<link rel="canonical" type="text/html" href="https://blog.huweihuang.com/kubernetes-notes/trouble-shooting/">
<link rel="alternate" type="application/rss&#43;xml" href="https://blog.huweihuang.com/kubernetes-notes/trouble-shooting/index.xml">
<meta name="robots" content="noindex, nofollow">


<link rel="shortcut icon" href="/favicons/favicon.ico" >
<link rel="apple-touch-icon" href="/favicons/apple-touch-icon-180x180.png" sizes="180x180">
<link rel="icon" type="image/png" href="/favicons/favicon-16x16.png" sizes="16x16">
<link rel="icon" type="image/png" href="/favicons/favicon-32x32.png" sizes="32x32">
<link rel="icon" type="image/png" href="/favicons/android-36x36.png" sizes="36x36">
<link rel="icon" type="image/png" href="/favicons/android-48x48.png" sizes="48x48">
<link rel="icon" type="image/png" href="/favicons/android-72x72.png" sizes="72x72">
<link rel="icon" type="image/png" href="/favicons/android-96x96.png" sizes="96x96">
<link rel="icon" type="image/png" href="/favicons/android-144x144.png" sizes="144x144">
<link rel="icon" type="image/png" href="/favicons/android-192x192.png" sizes="192x192">

<title>问题排查 | 胡伟煌</title>
<meta name="description" content="">
<meta property="og:title" content="问题排查" />
<meta property="og:description" content="Kubernetes学习笔记" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://blog.huweihuang.com/kubernetes-notes/trouble-shooting/" /><meta property="og:site_name" content="胡伟煌" />

<meta itemprop="name" content="问题排查">
<meta itemprop="description" content="Kubernetes学习笔记"><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="问题排查"/>
<meta name="twitter:description" content="Kubernetes学习笔记"/>




<link rel="preload" href="/scss/main.min.79e3930541ca05b5395c14b2a313b798fad1dc69f9a14aefa57b62eaa9f65f14.css" as="style">
<link href="/scss/main.min.79e3930541ca05b5395c14b2a313b798fad1dc69f9a14aefa57b62eaa9f65f14.css" rel="stylesheet" integrity="">

<script
  src="https://code.jquery.com/jquery-3.6.0.min.js"
  integrity="sha384-vtXRMe3mGCbOeY7l30aIg8H9p3GdeSe4IFlP6G8JMa7o7lXvnz3GFKzPxzJdPfGK"
  crossorigin="anonymous"></script>
<script
  src="https://unpkg.com/lunr@2.3.9/lunr.min.js"
  integrity="sha384-203J0SNzyqHby3iU6hzvzltrWi/M41wOP5Gu+BiJMz5nwKykbkUx8Kp7iti0Lpli"
  crossorigin="anonymous"></script>
<link rel="stylesheet" href="/css/prism.css"/>

<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-114718458-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

  </head>
  <body class="td-section">
    <header>
      
<nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar">
        <a class="navbar-brand" href="/">
		<span class="navbar-logo"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32" width="64" height="64"><path d="M15.9.476a2.14 2.14.0 00-.823.218L3.932 6.01c-.582.277-1.005.804-1.15 1.432L.054 19.373c-.13.56-.025 1.147.3 1.627q.057.087.12.168l7.7 9.574c.407.5 1.018.787 1.662.784h12.35c.646.001 1.258-.3 1.664-.793l7.696-9.576c.404-.5.555-1.16.4-1.786L29.2 7.43c-.145-.628-.57-1.155-1.15-1.432L16.923.695A2.14 2.14.0 0015.89.476z" fill="#326ce5"/><path d="M16.002 4.542c-.384.027-.675.356-.655.74v.188c.018.213.05.424.092.633a6.22 6.22.0 01.066 1.21c-.038.133-.114.253-.218.345l-.015.282c-.405.034-.807.096-1.203.186-1.666.376-3.183 1.24-4.354 2.485l-.24-.17c-.132.04-.274.025-.395-.04a6.22 6.22.0 01-.897-.81 5.55 5.55.0 00-.437-.465l-.148-.118c-.132-.106-.294-.167-.463-.175a.64.64.0 00-.531.236c-.226.317-.152.756.164.983l.138.11a5.55 5.55.0 00.552.323c.354.197.688.428.998.7a.74.74.0 01.133.384l.218.2c-1.177 1.766-1.66 3.905-1.358 6.006l-.28.08c-.073.116-.17.215-.286.288a6.22 6.22.0 01-1.194.197 5.57 5.57.0 00-.64.05l-.177.04h-.02a.67.67.0 00-.387 1.132.67.67.0 00.684.165h.013l.18-.02c.203-.06.403-.134.598-.218.375-.15.764-.265 1.162-.34.138.008.27.055.382.135l.3-.05c.65 2.017 2.016 3.726 3.84 4.803l-.122.255c.056.117.077.247.06.376-.165.382-.367.748-.603 1.092a5.58 5.58.0 00-.358.533l-.085.18a.67.67.0 00.65 1.001.67.67.0 00.553-.432l.083-.17c.076-.2.14-.404.192-.61.177-.437.273-.906.515-1.196a.54.54.0 01.286-.14l.15-.273a8.62 8.62.0 006.146.015l.133.255c.136.02.258.095.34.205.188.358.34.733.456 1.12a5.57 5.57.0 00.194.611l.083.17a.67.67.0 001.187.131.67.67.0 00.016-.701l-.087-.18a5.55 5.55.0 00-.358-.531c-.23-.332-.428-.686-.6-1.057a.52.52.0 01.068-.4 2.29 2.29.0 01-.111-.269c1.82-1.085 3.18-2.8 3.823-4.82l.284.05c.102-.093.236-.142.373-.138.397.076.786.2 1.162.34.195.09.395.166.598.23.048.013.118.024.172.037h.013a.67.67.0 00.841-.851.67.67.0 00-.544-.446l-.194-.046a5.57 5.57.0 00-.64-.05c-.404-.026-.804-.092-1.194-.197-.12-.067-.22-.167-.288-.288l-.27-.08a8.65 8.65.0 00-1.386-5.993l.236-.218c-.01-.137.035-.273.124-.378.307-.264.64-.497.99-.696a5.57 5.57.0 00.552-.323l.146-.118a.67.67.0 00-.133-1.202.67.67.0 00-.696.161l-.148.118a5.57 5.57.0 00-.437.465c-.264.302-.556.577-.873.823a.74.74.0 01-.404.044l-.253.18c-1.46-1.53-3.427-2.48-5.535-2.67.0-.1-.013-.25-.015-.297-.113-.078-.192-.197-.218-.332a6.23 6.23.0 01.076-1.207c.043-.21.073-.42.092-.633v-.2c.02-.384-.27-.713-.655-.74zm-.834 5.166-.2 3.493h-.015c-.01.216-.137.4-.332.504s-.426.073-.6-.054l-2.865-2.03a6.86 6.86.0 013.303-1.799c.234-.05.47-.088.707-.114zm1.668.0c1.505.187 2.906.863 3.99 1.924l-2.838 2.017c-.175.14-.415.168-.618.072s-.333-.3-.336-.524zm-6.72 3.227 2.62 2.338v.015c.163.142.234.363.186.574s-.21.378-.417.435v.01l-3.362.967a6.86 6.86.0 01.974-4.34zm11.753.0c.796 1.295 1.148 2.814 1.002 4.327l-3.367-.97v-.013c-.21-.057-.37-.224-.417-.435s.023-.43.186-.574l2.6-2.327zm-6.404 2.52h1.072l.655.832-.238 1.04-.963.463-.965-.463-.227-1.04zm3.434 2.838c.045-.005.1-.005.135.0l3.467.585c-.5 1.44-1.487 2.67-2.775 3.493l-1.34-3.244a.59.59.0 01.509-.819zm-5.823.015c.196.003.377.104.484.268s.124.37.047.55v.013l-1.332 3.218C11 21.54 10.032 20.325 9.517 18.9l3.437-.583c.038-.004.077-.004.116.0zm2.904 1.4a.59.59.0 01.537.308h.013l1.694 3.057-.677.2c-1.246.285-2.547.218-3.758-.194l1.7-3.057c.103-.18.293-.29.5-.295z" fill="#fff" stroke="#fff" stroke-width=".055"/></svg></span><span class="font-weight-bold">胡伟煌</span>
	</a>
	<div class="td-navbar-nav-scroll ml-md-auto" id="main_navbar">
		<ul class="navbar-nav mt-2 mt-lg-0">
			
			
			<li class="nav-item mr-4 mb-2 mb-lg-0">
				
				
				
				
				
				
				
				
				<a class="nav-link active" href="/kubernetes-notes/" ><span class="active">Kubernetes学习笔记</span></a>
			</li>
			
			<li class="nav-item mr-4 mb-2 mb-lg-0">
				
				
				
				
				
				
				
				
				<a class="nav-link" href="/k8s-source-code-analysis/" ><span>Kubernetes源码分析</span></a>
			</li>
			
			<li class="nav-item mr-4 mb-2 mb-lg-0">
				
				
				
				
				
				
				
				
				<a class="nav-link" href="/golang-notes/" ><span>Golang学习笔记</span></a>
			</li>
			
			<li class="nav-item mr-4 mb-2 mb-lg-0">
				
				
				
				
				
				
				
				
				<a class="nav-link" href="/linux-notes/" ><span>Linux学习笔记</span></a>
			</li>
			
			<li class="nav-item mr-4 mb-2 mb-lg-0">
				
				
				
				
				
				
				
				
				<a class="nav-link" href="/about/" ><span>About</span></a>
			</li>
			
			
			
		</ul>
	</div>
	<div class="navbar-nav d-none d-lg-block"><input
  type="search"
  class="form-control td-search-input"
  placeholder="&#xf002; 站内搜索…"
  aria-label="站内搜索…"
  autocomplete="off"
  
  data-offline-search-index-json-src="/offline-search-index.8f38458ed036ae235aaab0d3a80ec8cb.json"
  data-offline-search-base-href="/"
  data-offline-search-max-results="10"
>
</div>
</nav>

    </header>
    <div class="container-fluid td-outer">
      <div class="td-main">
        <div class="row flex-xl-nowrap">
          <main class="col-12 col-md-9 col-xl-8 pl-md-5" role="main">
            




<div class="td-content">
<div class="pageinfo pageinfo-primary d-print-none">
<p>
这是本节的多页打印视图。
<a href="#" onclick="print();return false;">点击此处打印</a>.
</p><p>
<a href="/kubernetes-notes/trouble-shooting/">返回本页常规视图</a>.
</p>
</div>



<h1 class="title">问题排查</h1>





    <ul>
    
  
  
  
  

  
    
    
	
<li>1: <a href="#pg-5e242ea47c9c787791d59cd163945da5">节点问题</a></li>


    
    <ul>
        
  
  
  
  

  
    
    
	
<li>1.1: <a href="#pg-9266a42ddd092ba43bf3d72f0dce8cad">keycreate permission denied</a></li>


    
  
    
    
	
<li>1.2: <a href="#pg-97ba76b50b571d95b673a250d703d2c2">Cgroup不支持pid资源</a></li>


    
  
    
    
	
<li>1.3: <a href="#pg-53caa084b28bad6e76e4c0659db83524">Cgroup子系统无法挂载</a></li>


    
  
    
    
	
<li>1.4: <a href="#pg-be6ea3f2a598a7462ad23ef96ba1c6c7">runc-v1.1.3-exec-failed</a></li>


    
  
    
    
	
<li>1.5: <a href="#pg-a78e18cade1826f4b4c0178fa69df716">increase the mlock limit</a></li>


    
  

    </ul>
    
  
    
    
	
<li>2: <a href="#pg-6e5d6353511fecf4ee5dd3d2d1c2d36a">Pod驱逐</a></li>


    
  
    
    
	
<li>3: <a href="#pg-4a6e864a3e311d3029ea0182a946f368">镜像拉取失败问题</a></li>


    
  
    
    
	
<li>4: <a href="#pg-f2cc121604cda28beccb98599cfa50cc">PVC Terminating</a></li>


    
  
    
    
	
<li>5: <a href="#pg-1fc63b5dc9513028d22327de8b197dcf">ConfigMap多行格式</a></li>


    
  

    </ul>


<div class="content">
      
</div>
</div>


  
  
  
  

  
  

  
    
    
	
    

<div class="td-content" style="">
    
	<h1 id="pg-5e242ea47c9c787791d59cd163945da5">1 - 节点问题</h1>
    
	
</div>



    
      
  
  
  
  

  
  

  
    
    
	
    

<div class="td-content" style="">
    
	<h1 id="pg-9266a42ddd092ba43bf3d72f0dce8cad">1.1 - keycreate permission denied</h1>
    
	<h1 id="问题描述">问题描述</h1>
<pre tabindex="0"><code>write /proc/self/attr/keycreate: permission denied
</code></pre><p>具体报错：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kuberuntime_manager.go:758<span style="color:#ce5c00;font-weight:bold">]</span> createPodSandbox <span style="color:#204a87;font-weight:bold">for</span> pod <span style="color:#4e9a06">&#34;ecc-hostpath-provisioner-8jbhf_kube-system(b8050fd3-4ffe-11eb-a82e-c6090b53405b)&#34;</span> failed: rpc error: <span style="color:#000">code</span> <span style="color:#ce5c00;font-weight:bold">=</span> Unknown <span style="color:#000">desc</span> <span style="color:#ce5c00;font-weight:bold">=</span> failed to start sandbox container <span style="color:#204a87;font-weight:bold">for</span> pod <span style="color:#4e9a06">&#34;ecc-hostpath-provisioner-8jbhf&#34;</span>: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused <span style="color:#4e9a06">&#34;process_linux.go:449: container init caused \&#34;write /proc/self/attr/keycreate: permission denied\&#34;&#34;</span>: unknown
</span></span></code></pre></div><h1 id="解决办法">解决办法</h1>
<p>SELINUX未设置成disabled</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># 将SELINUX设置成disabled</span>
</span></span><span style="display:flex;"><span>setenforce <span style="color:#0000cf;font-weight:bold">0</span> <span style="color:#8f5902;font-style:italic"># 临时生效</span>
</span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># 永久生效，但需重启，配合上述命令可以不用立即重启</span>
</span></span><span style="display:flex;"><span>sed -i <span style="color:#4e9a06">&#34;s/SELINUX=enforcing/SELINUX=disabled/g&#34;</span> /etc/selinux/config
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># 查看SELinux状态</span>
</span></span><span style="display:flex;"><span>$ /usr/sbin/sestatus -v 
</span></span><span style="display:flex;"><span>SELinux status:                 disabled
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>$ getenforce
</span></span><span style="display:flex;"><span>Disabled
</span></span></code></pre></div>
</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-97ba76b50b571d95b673a250d703d2c2">1.2 - Cgroup不支持pid资源</h1>
    
	<h1 id="问题描述">问题描述</h1>
<p>机器内核版本较低，kubelet启动异常，报错如下：</p>
<pre tabindex="0"><code>Failed to start ContainerManager failed to initialize top level QOS containers: failed to update top level Burstable QOS cgroup : failed to set supported cgroup subsystems for cgroup [kubepods burstable]: Failed to find subsystem mount for required subsystem: pids
</code></pre><h1 id="原因分析">原因分析</h1>
<p>低版本内核的cgroup不支持pids资源的功能，</p>
<pre tabindex="0"><code>cat /proc/cgroups
#subsys_name	hierarchy	num_cgroups	enabled
cpuset	5	6	1
cpu	2	76	1
cpuacct	2	76	1
memory	4	76	1
devices	10	76	1
freezer	7	6	1
net_cls	3	6	1
blkio	8	76	1
perf_event	9	6	1
hugetlb	6	6	1
</code></pre><p>正常机器的cgroup</p>
<pre tabindex="0"><code>root@host:~# cat /proc/cgroups
#subsys_name	hierarchy	num_cgroups	enabled
cpuset	5	17	1
cpu	7	80	1
cpuacct	7	80	1
memory	12	80	1
devices	10	80	1
freezer	2	17	1
net_cls	4	17	1
blkio	8	80	1
perf_event	6	17	1
hugetlb	11	17	1
pids	3	80	1    # 此处支持pids资源
oom	9	1	1
</code></pre><h1 id="解决方案">解决方案</h1>
<p>1、升级内核版本，使得cgroup支持pids资源。</p>
<p>或者</p>
<p>2、将kubelet的启动参数添加 SupportPodPidsLimit=false,SupportNodePidsLimit=false</p>
<pre tabindex="0"><code>vi /etc/systemd/system/kubelet.service

# 添加 kubelet 启动参数 
--feature-gates=... ,SupportPodPidsLimit=false,SupportNodePidsLimit=false \

systemctl daemon-reload &amp;&amp; systemctl restart kubelet.service
</code></pre><p>文档参考：</p>
<ul>
<li>
<p><a href="https://kubernetes.io/zh/blog/2019/04/15/kubernetes-1.14-%E7%A8%B3%E5%AE%9A%E6%80%A7%E6%94%B9%E8%BF%9B%E4%B8%AD%E7%9A%84%E8%BF%9B%E7%A8%8Bid%E9%99%90%E5%88%B6/">Kubernetes 1.14 稳定性改进中的进程ID限制</a></p>
</li>
<li>
<p><a href="https://blog.csdn.net/qq_38900565/article/details/100707025">https://blog.csdn.net/qq_38900565/article/details/100707025</a></p>
</li>
<li>
<p><a href="https://adoyle.me/Today-I-Learned/k8s/k8s-deployment.html">https://adoyle.me/Today-I-Learned/k8s/k8s-deployment.html</a></p>
</li>
</ul>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-53caa084b28bad6e76e4c0659db83524">1.3 - Cgroup子系统无法挂载</h1>
    
	<h1 id="问题描述">问题描述</h1>
<p>内核版本： 5.4.56-200.el7.x86_64</p>
<p>docker报错</p>
<pre tabindex="0"><code>May 13 16:54:26 8b26d7a8 dockerd[44352]: time=&#34;2021-05-13T16:54:26.565235530+08:00&#34; level=warning msg=&#34;failed to load plugin io.containerd.snapshotter.v1.devmapper&#34; error=&#34;devmapper not configured&#34;
May 13 16:54:26 8b26d7a8 dockerd[44352]: time=&#34;2021-05-13T16:54:26.565525512+08:00&#34; level=warning msg=&#34;could not use snapshotter devmapper in metadata plugin&#34; error=&#34;devmapper not configured&#34;
May 13 16:54:26 8b26d7a8 dockerd[44352]: time=&#34;2021-05-13T16:54:26.574734345+08:00&#34; level=warning msg=&#34;Your kernel does not support CPU realtime scheduler&#34;
May 13 16:54:26 8b26d7a8 dockerd[44352]: time=&#34;2021-05-13T16:54:26.574792864+08:00&#34; level=warning msg=&#34;Your kernel does not support cgroup blkio weight&#34;
May 13 16:54:26 8b26d7a8 dockerd[44352]: time=&#34;2021-05-13T16:54:26.574800326+08:00&#34; level=warning msg=&#34;Your kernel does not support cgroup blkio weight_device&#34;
</code></pre><p>kubelet报错</p>
<p><img src="../../images/troubleshooting/cgroup-not-mount.png" alt="kubelet"></p>
<h1 id="解决">解决</h1>
<p>cgroup问题解决：</p>
<p>1、curl <a href="https://pi-ops.oss-cn-hangzhou.aliyuncs.com/scripts/cgroupfs-mount.sh">https://pi-ops.oss-cn-hangzhou.aliyuncs.com/scripts/cgroupfs-mount.sh</a> | bash</p>
<p>2、重启设备即可解决</p>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-be6ea3f2a598a7462ad23ef96ba1c6c7">1.4 - runc-v1.1.3-exec-failed</h1>
    
	<h2 id="问题描述">问题描述</h2>
<p>当使用<code>runc 1.1.3</code>的版本时，如果执行<code>systemctl daemon-reload</code>后，通过exec进入容器则会触发以下错误，无法进入容器。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>FATA<span style="color:#ce5c00;font-weight:bold">[</span>0000<span style="color:#ce5c00;font-weight:bold">]</span> execing <span style="color:#204a87">command</span> in container: Internal error occurred: error executing <span style="color:#204a87">command</span> in container: failed to <span style="color:#204a87">exec</span> in container: failed to start <span style="color:#204a87">exec</span> <span style="color:#4e9a06">&#34;33d05b4f71a2da69c8c77cc3f7e61451814eb150edd15d0a3153b57a862126d4&#34;</span>: OCI runtime <span style="color:#204a87">exec</span> failed: <span style="color:#204a87">exec</span> failed: unable to start container process: open /dev/pts/0: operation not permitted: unknown
</span></span></code></pre></div><h2 id="原因">原因</h2>
<p>这个是runc 1.1.3版本起存在的一个bug，runc1.1.2的版本不存在，社区在runc 1.1.4的版本中修复了这个bug。由于 runc v1.1.3 中不再添加 <code>DeviceAllow=char-pts rwm</code> 规则了，当执行 <code>systemctl daemon-reload</code> 后， 会导致重新应用 systemd 的规则，进而导致这条规则的缺失。</p>
<h2 id="解决方案">解决方案</h2>
<p>升级runc到1.1.4的版本，并且所有通过runc1.1.3创建的pod都需要重建才能生效。</p>
<p>参考：</p>
<ul>
<li>
<p><a href="https://github.com/containerd/containerd/issues/7219#issuecomment-1225358826">https://github.com/containerd/containerd/issues/7219#issuecomment-1225358826</a></p>
</li>
<li>
<p><a href="https://github.com/opencontainers/runc/issues/3551">https://github.com/opencontainers/runc/issues/3551</a></p>
</li>
<li>
<p><a href="https://github.com/opencontainers/runc/releases/tag/v1.1.4">Release runc 1.1.4 -- &quot;If you look for perfection, you'll never be content.&quot; · opencontainers/runc · GitHub</a></p>
</li>
</ul>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-a78e18cade1826f4b4c0178fa69df716">1.5 - increase the mlock limit</h1>
    
	<h2 id="问题描述">问题描述</h2>
<p>容器启动报错：increase the mlock limit，原因是ulimit mlock值比较小，需要将ulimit值调大。</p>
<p>报错如下：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>runtime: mlock of signal stack failed: <span style="color:#0000cf;font-weight:bold">12</span>
</span></span><span style="display:flex;"><span>runtime: increase the mlock limit <span style="color:#ce5c00;font-weight:bold">(</span><span style="color:#204a87">ulimit</span> -l<span style="color:#ce5c00;font-weight:bold">)</span> or
</span></span><span style="display:flex;"><span>runtime: update your kernel to 5.3.15+, 5.4.2+, or 5.5+
</span></span><span style="display:flex;"><span>fatal error: mlock failed
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>runtime stack:
</span></span><span style="display:flex;"><span>runtime.throw<span style="color:#ce5c00;font-weight:bold">(</span>0x1a7729f, 0xc<span style="color:#ce5c00;font-weight:bold">)</span>
</span></span><span style="display:flex;"><span>    /usr/local/go/src/runtime/panic.go:1112 +0x72
</span></span><span style="display:flex;"><span>runtime.mlockGsignal<span style="color:#ce5c00;font-weight:bold">(</span>0xc000702300<span style="color:#ce5c00;font-weight:bold">)</span>
</span></span><span style="display:flex;"><span>    /usr/local/go/src/runtime/os_linux_x86.go:72 +0x107
</span></span><span style="display:flex;"><span>runtime.mpreinit<span style="color:#ce5c00;font-weight:bold">(</span>0xc000588380<span style="color:#ce5c00;font-weight:bold">)</span>
</span></span><span style="display:flex;"><span>    /usr/local/go/src/runtime/os_linux.go:341 +0x78
</span></span><span style="display:flex;"><span>runtime.mcommoninit<span style="color:#ce5c00;font-weight:bold">(</span>0xc000588380<span style="color:#ce5c00;font-weight:bold">)</span>
</span></span><span style="display:flex;"><span>    /usr/local/go/src/runtime/proc.go:630 +0x108
</span></span><span style="display:flex;"><span>runtime.allocm<span style="color:#ce5c00;font-weight:bold">(</span>0xc000072000, 0x1adcb70, 0x0<span style="color:#ce5c00;font-weight:bold">)</span>
</span></span><span style="display:flex;"><span>    /usr/local/go/src/runtime/proc.go:1390 +0x14e
</span></span><span style="display:flex;"><span>runtime.newm<span style="color:#ce5c00;font-weight:bold">(</span>0x1adcb70, 0xc000072000<span style="color:#ce5c00;font-weight:bold">)</span>
</span></span><span style="display:flex;"><span>    /usr/local/go/src/runtime/proc.go:1704 +0x39
</span></span><span style="display:flex;"><span>runtime.startm<span style="color:#ce5c00;font-weight:bold">(</span>0x0, 0xc000267e01<span style="color:#ce5c00;font-weight:bold">)</span>
</span></span><span style="display:flex;"><span>    /usr/local/go/src/runtime/proc.go:1869 +0x12a
</span></span><span style="display:flex;"><span>runtime.wakep<span style="color:#ce5c00;font-weight:bold">(</span>...<span style="color:#ce5c00;font-weight:bold">)</span>
</span></span><span style="display:flex;"><span>    /usr/local/go/src/runtime/proc.go:1953
</span></span><span style="display:flex;"><span>runtime.resetspinning<span style="color:#ce5c00;font-weight:bold">()</span>
</span></span><span style="display:flex;"><span>    /usr/local/go/src/runtime/proc.go:2415 +0x93
</span></span><span style="display:flex;"><span>runtime.schedule<span style="color:#ce5c00;font-weight:bold">()</span>
</span></span><span style="display:flex;"><span>    /usr/local/go/src/runtime/proc.go:2527 +0x2de
</span></span><span style="display:flex;"><span>runtime.mstart1<span style="color:#ce5c00;font-weight:bold">()</span>
</span></span><span style="display:flex;"><span>    /usr/local/go/src/runtime/proc.go:1104 +0x8e
</span></span><span style="display:flex;"><span>runtime.mstart<span style="color:#ce5c00;font-weight:bold">()</span>
</span></span><span style="display:flex;"><span>    /usr/local/go/src/runtime/proc.go:1062 +0x6e
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>goroutine <span style="color:#0000cf;font-weight:bold">1</span> <span style="color:#ce5c00;font-weight:bold">[</span>runnable, locked to thread<span style="color:#ce5c00;font-weight:bold">]</span>:
</span></span><span style="display:flex;"><span>github.com/xdg/stringprep.init<span style="color:#ce5c00;font-weight:bold">()</span>
</span></span><span style="display:flex;"><span>    /root/go/pkg/mod/github.com/xdg/stringprep@v1.0.3/tables.go:443 +0x19087
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>goroutine <span style="color:#0000cf;font-weight:bold">43</span> <span style="color:#ce5c00;font-weight:bold">[</span><span style="color:#204a87;font-weight:bold">select</span><span style="color:#ce5c00;font-weight:bold">]</span>:
</span></span><span style="display:flex;"><span>go.opencensus.io/stats/view.<span style="color:#ce5c00;font-weight:bold">(</span>*worker<span style="color:#ce5c00;font-weight:bold">)</span>.start<span style="color:#ce5c00;font-weight:bold">(</span>0xc00067e800<span style="color:#ce5c00;font-weight:bold">)</span>
</span></span><span style="display:flex;"><span>    /root/go/pkg/mod/go.opencensus.io@v0.23.0/stats/view/worker.go:276 +0x100
</span></span><span style="display:flex;"><span>created by go.opencensus.io/stats/view.init.0
</span></span><span style="display:flex;"><span>    /root/go/pkg/mod/go.opencensus.io@v0.23.0/stats/view/worker.go:34 +0x68
</span></span></code></pre></div><h2 id="原因">原因</h2>
<p>宿主机的ulimit值比较小，需要将内存的ulimit值调大。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ <span style="color:#204a87">ulimit</span> -l
</span></span><span style="display:flex;"><span><span style="color:#0000cf;font-weight:bold">64</span>
</span></span></code></pre></div><h2 id="解决方案">解决方案</h2>
<p>vi /lib/systemd/system/containerd.service。在containerd.service文件中增加<code>LimitMEMLOCK=infinity</code> 参数。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#ce5c00;font-weight:bold">[</span>Unit<span style="color:#ce5c00;font-weight:bold">]</span>
</span></span><span style="display:flex;"><span><span style="color:#000">Description</span><span style="color:#ce5c00;font-weight:bold">=</span>containerd container runtime
</span></span><span style="display:flex;"><span><span style="color:#000">Documentation</span><span style="color:#ce5c00;font-weight:bold">=</span>https://containerd.io
</span></span><span style="display:flex;"><span><span style="color:#000">After</span><span style="color:#ce5c00;font-weight:bold">=</span>network.target local-fs.target
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ce5c00;font-weight:bold">[</span>Service<span style="color:#ce5c00;font-weight:bold">]</span>
</span></span><span style="display:flex;"><span><span style="color:#000">ExecStartPre</span><span style="color:#ce5c00;font-weight:bold">=</span>-/sbin/modprobe overlay
</span></span><span style="display:flex;"><span><span style="color:#000">ExecStart</span><span style="color:#ce5c00;font-weight:bold">=</span>/usr/local/bin/containerd
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#000">Type</span><span style="color:#ce5c00;font-weight:bold">=</span>notify
</span></span><span style="display:flex;"><span><span style="color:#000">Delegate</span><span style="color:#ce5c00;font-weight:bold">=</span>yes
</span></span><span style="display:flex;"><span><span style="color:#000">KillMode</span><span style="color:#ce5c00;font-weight:bold">=</span>process
</span></span><span style="display:flex;"><span><span style="color:#000">Restart</span><span style="color:#ce5c00;font-weight:bold">=</span>always
</span></span><span style="display:flex;"><span><span style="color:#000">RestartSec</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#0000cf;font-weight:bold">5</span>
</span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># Having non-zero Limit*s causes performance problems due to accounting overhead</span>
</span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># in the kernel. We recommend using cgroups to do container-local accounting.</span>
</span></span><span style="display:flex;"><span><span style="color:#000">LimitMEMLOCK</span><span style="color:#ce5c00;font-weight:bold">=</span>infinity
</span></span><span style="display:flex;"><span><span style="color:#000">LimitNPROC</span><span style="color:#ce5c00;font-weight:bold">=</span>infinity
</span></span><span style="display:flex;"><span><span style="color:#000">LimitCORE</span><span style="color:#ce5c00;font-weight:bold">=</span>infinity
</span></span><span style="display:flex;"><span><span style="color:#000">LimitNOFILE</span><span style="color:#ce5c00;font-weight:bold">=</span>infinity
</span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># Comment TasksMax if your systemd version does not supports it.</span>
</span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># Only systemd 226 and above support this version.</span>
</span></span><span style="display:flex;"><span><span style="color:#000">TasksMax</span><span style="color:#ce5c00;font-weight:bold">=</span>infinity
</span></span><span style="display:flex;"><span><span style="color:#000">OOMScoreAdjust</span><span style="color:#ce5c00;font-weight:bold">=</span>-999
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ce5c00;font-weight:bold">[</span>Install<span style="color:#ce5c00;font-weight:bold">]</span>
</span></span><span style="display:flex;"><span><span style="color:#000">WantedBy</span><span style="color:#ce5c00;font-weight:bold">=</span>multi-user.target
</span></span></code></pre></div><p>重启containerd</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>systemctl daemon-reload
</span></span><span style="display:flex;"><span>systemctl restart containerd
</span></span><span style="display:flex;"><span>systemctl status containerd
</span></span></code></pre></div>
</div>



    
	
  

    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-6e5d6353511fecf4ee5dd3d2d1c2d36a">2 - Pod驱逐</h1>
    
	<h1 id="问题描述">问题描述</h1>
<p>节点Pod被驱逐</p>
<h1 id="原因">原因</h1>
<h2 id="1-查看节点和该节点pod状态">1. 查看节点和该节点pod状态</h2>
<p>查看节点状态为Ready，查看该节点的所有pod，发现存在被驱逐的pod和nvidia-device-plugin为pending</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>root@host:~$ kgpoallowide <span style="color:#000;font-weight:bold">|</span>grep 192.168.1.1
</span></span><span style="display:flex;"><span>department-56   173e397c-ea35-4aac-85d8-07106e55d7b7   0/1       Evicted             <span style="color:#0000cf;font-weight:bold">0</span>          52d       &lt;none&gt;            192.168.1.1   &lt;none&gt;
</span></span><span style="display:flex;"><span>kube-system     nvidia-device-plugin-daemonset-d58d2   0/1       Pending             <span style="color:#0000cf;font-weight:bold">0</span>          1s        &lt;none&gt;            192.168.1.1   &lt;none&gt;
</span></span></code></pre></div><h2 id="2-查看对应节点kubelet的日志">2. 查看对应节点kubelet的日志</h2>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#0000cf;font-weight:bold">0905</span> 15:42:13.182280   <span style="color:#0000cf;font-weight:bold">23506</span> eviction_manager.go:142<span style="color:#ce5c00;font-weight:bold">]</span> Failed to admit pod rdma-device-plugin-daemonset-8nwb8_kube-system<span style="color:#ce5c00;font-weight:bold">(</span>acc28a85-cfb0-11e9-9729-6c92bf5e2432<span style="color:#ce5c00;font-weight:bold">)</span> - node has conditions: <span style="color:#ce5c00;font-weight:bold">[</span>DiskPressure<span style="color:#ce5c00;font-weight:bold">]</span>
</span></span><span style="display:flex;"><span>I0905 15:42:14.827343   <span style="color:#0000cf;font-weight:bold">23506</span> kubelet.go:1836<span style="color:#ce5c00;font-weight:bold">]</span> SyncLoop <span style="color:#ce5c00;font-weight:bold">(</span>ADD, <span style="color:#4e9a06">&#34;api&#34;</span><span style="color:#ce5c00;font-weight:bold">)</span>: <span style="color:#4e9a06">&#34;nvidia-device-plugin-daemonset-88sm6_kube-system(adbd9227-cfb0-11e9-9729-6c92bf5e2432)&#34;</span>
</span></span><span style="display:flex;"><span>W0905 15:42:14.827372   <span style="color:#0000cf;font-weight:bold">23506</span> eviction_manager.go:142<span style="color:#ce5c00;font-weight:bold">]</span> Failed to admit pod nvidia-device-plugin-daemonset-88sm6_kube-system<span style="color:#ce5c00;font-weight:bold">(</span>adbd9227-cfb0-11e9-9729-6c92bf5e2432<span style="color:#ce5c00;font-weight:bold">)</span> - node has conditions: <span style="color:#ce5c00;font-weight:bold">[</span>DiskPressure<span style="color:#ce5c00;font-weight:bold">]</span>
</span></span><span style="display:flex;"><span>I0905 15:42:15.722378   <span style="color:#0000cf;font-weight:bold">23506</span> kubelet_node_status.go:607<span style="color:#ce5c00;font-weight:bold">]</span> Update capacity <span style="color:#204a87;font-weight:bold">for</span> nvidia.com/gpu-share to <span style="color:#0000cf;font-weight:bold">0</span>
</span></span><span style="display:flex;"><span>I0905 15:42:16.692488   <span style="color:#0000cf;font-weight:bold">23506</span> kubelet.go:1852<span style="color:#ce5c00;font-weight:bold">]</span> SyncLoop <span style="color:#ce5c00;font-weight:bold">(</span>DELETE, <span style="color:#4e9a06">&#34;api&#34;</span><span style="color:#ce5c00;font-weight:bold">)</span>: <span style="color:#4e9a06">&#34;rdma-device-plugin-daemonset-8nwb8_kube-system(acc28a85-cfb0-11e9-9729-6c92bf5e2432)&#34;</span>
</span></span><span style="display:flex;"><span>W0905 15:42:16.698445   <span style="color:#0000cf;font-weight:bold">23506</span> status_manager.go:489<span style="color:#ce5c00;font-weight:bold">]</span> Failed to delete status <span style="color:#204a87;font-weight:bold">for</span> pod <span style="color:#4e9a06">&#34;rdma-device-plugin-daemonset-8nwb8_kube-system(acc28a85-cfb0-11e9-9729-6c92bf5e2432)&#34;</span>: pod <span style="color:#4e9a06">&#34;rdma-device-plugin-daemonset-8nwb8&#34;</span> not found
</span></span><span style="display:flex;"><span>I0905 15:42:16.698490   <span style="color:#0000cf;font-weight:bold">23506</span> kubelet.go:1846<span style="color:#ce5c00;font-weight:bold">]</span> SyncLoop <span style="color:#ce5c00;font-weight:bold">(</span>REMOVE, <span style="color:#4e9a06">&#34;api&#34;</span><span style="color:#ce5c00;font-weight:bold">)</span>: <span style="color:#4e9a06">&#34;rdma-device-plugin-daemonset-8nwb8_kube-system(acc28a85-cfb0-11e9-9729-6c92bf5e2432)&#34;</span>
</span></span><span style="display:flex;"><span>I0905 15:42:16.699267   <span style="color:#0000cf;font-weight:bold">23506</span> kubelet.go:2040<span style="color:#ce5c00;font-weight:bold">]</span> Failed to delete pod <span style="color:#4e9a06">&#34;rdma-device-plugin-daemonset-8nwb8_kube-system(acc28a85-cfb0-11e9-9729-6c92bf5e2432)&#34;</span>, err: pod not found
</span></span><span style="display:flex;"><span>W0905 15:42:16.777355   <span style="color:#0000cf;font-weight:bold">23506</span> eviction_manager.go:332<span style="color:#ce5c00;font-weight:bold">]</span> eviction manager: attempting to reclaim nodefs
</span></span><span style="display:flex;"><span>I0905 15:42:16.777384   <span style="color:#0000cf;font-weight:bold">23506</span> eviction_manager.go:346<span style="color:#ce5c00;font-weight:bold">]</span> eviction manager: must evict pod<span style="color:#ce5c00;font-weight:bold">(</span>s<span style="color:#ce5c00;font-weight:bold">)</span> to reclaim nodefs
</span></span><span style="display:flex;"><span>E0905 15:42:16.777390   <span style="color:#0000cf;font-weight:bold">23506</span> eviction_manager.go:357<span style="color:#ce5c00;font-weight:bold">]</span> eviction manager: eviction thresholds have been met, but no pods are active to evict
</span></span></code></pre></div><p>存在关于pod驱逐相关的日志，驱逐的原因为<code>node has conditions: [DiskPressure]</code>。</p>
<h2 id="3-查看磁盘相关信息">3. 查看磁盘相关信息</h2>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#ce5c00;font-weight:bold">[</span>root@host /<span style="color:#ce5c00;font-weight:bold">]</span><span style="color:#8f5902;font-style:italic"># df -h</span>
</span></span><span style="display:flex;"><span>Filesystem      Size  Used Avail Use% Mounted on
</span></span><span style="display:flex;"><span>devtmpfs        126G     <span style="color:#0000cf;font-weight:bold">0</span>  126G   0% /dev
</span></span><span style="display:flex;"><span>tmpfs           126G     <span style="color:#0000cf;font-weight:bold">0</span>  126G   0% /dev/shm
</span></span><span style="display:flex;"><span>tmpfs           126G   27M  126G   1% /run
</span></span><span style="display:flex;"><span>tmpfs           126G     <span style="color:#0000cf;font-weight:bold">0</span>  126G   0% /sys/fs/cgroup
</span></span><span style="display:flex;"><span>/dev/sda1        20G   19G     <span style="color:#0000cf;font-weight:bold">0</span> 100% /   <span style="color:#8f5902;font-style:italic"># 根目录磁盘满</span>
</span></span><span style="display:flex;"><span>/dev/nvme1n1    3.0T  191G  2.8T   7% /data2
</span></span><span style="display:flex;"><span>/dev/nvme0n1    3.0T  1.3T  1.7T  44% /data1
</span></span><span style="display:flex;"><span>/dev/sda4       182G   95G   87G  53% /data
</span></span><span style="display:flex;"><span>/dev/sda3        20G  3.8G   15G  20% /usr/local
</span></span><span style="display:flex;"><span>tmpfs            26G     <span style="color:#0000cf;font-weight:bold">0</span>   26G   0% /run/user/0
</span></span></code></pre></div><p>发现根目录的磁盘盘，接着查看哪些文件占用磁盘。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#ce5c00;font-weight:bold">[</span>root@host ~/kata<span style="color:#ce5c00;font-weight:bold">]</span><span style="color:#8f5902;font-style:italic"># du -sh ./*</span>
</span></span><span style="display:flex;"><span>1.0M	./log
</span></span><span style="display:flex;"><span>944K	./netlink
</span></span><span style="display:flex;"><span>6.6G	./kernel3
</span></span></code></pre></div><p>/var/log/下存在7G 的日志。清理相关日志和无用文件后，根目录恢复空间。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#ce5c00;font-weight:bold">[</span>root@host /data<span style="color:#ce5c00;font-weight:bold">]</span><span style="color:#8f5902;font-style:italic"># df -h</span>
</span></span><span style="display:flex;"><span>Filesystem      Size  Used Avail Use% Mounted on
</span></span><span style="display:flex;"><span>devtmpfs        126G     <span style="color:#0000cf;font-weight:bold">0</span>  126G   0% /dev
</span></span><span style="display:flex;"><span>tmpfs           126G     <span style="color:#0000cf;font-weight:bold">0</span>  126G   0% /dev/shm
</span></span><span style="display:flex;"><span>tmpfs           126G   27M  126G   1% /run
</span></span><span style="display:flex;"><span>tmpfs           126G     <span style="color:#0000cf;font-weight:bold">0</span>  126G   0% /sys/fs/cgroup
</span></span><span style="display:flex;"><span>/dev/sda1        20G  5.8G   13G  32% /   <span style="color:#8f5902;font-style:italic"># 根目录正常</span>
</span></span><span style="display:flex;"><span>/dev/nvme1n1    3.0T  191G  2.8T   7% /data2
</span></span></code></pre></div><p>查看节点pod状态，相关plugin的pod恢复正常。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>root@host:~$ kgpoallowide <span style="color:#000;font-weight:bold">|</span>grep 192.168.1.1
</span></span><span style="display:flex;"><span>kube-system     nvidia-device-plugin-daemonset-h4pjc   1/1       Running             <span style="color:#0000cf;font-weight:bold">0</span>          16m       192.168.1.1   192.168.1.1   &lt;none&gt;
</span></span><span style="display:flex;"><span>kube-system     rdma-device-plugin-daemonset-xlkbv     1/1       Running             <span style="color:#0000cf;font-weight:bold">0</span>          16m       192.168.1.1   192.168.1.1   &lt;none&gt;
</span></span></code></pre></div><h2 id="4-查看kubelet配置">4. 查看kubelet配置</h2>
<p>查看kubelet关于pod驱逐相关的参数配置，可见节点kubelet开启了驱逐机制，正常情况下该配置应该是关闭的。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#000">ExecStart</span><span style="color:#ce5c00;font-weight:bold">=</span>/usr/local/bin/kubelet <span style="color:#4e9a06">\
</span></span></span><span style="display:flex;"><span><span style="color:#4e9a06"></span>	...
</span></span><span style="display:flex;"><span>  --eviction-hard<span style="color:#ce5c00;font-weight:bold">=</span>nodefs.available&lt;1% <span style="color:#4e9a06">\
</span></span></span></code></pre></div><h1 id="解决方案">解决方案</h1>
<p>总结以上原因为，kubelet开启了pod驱逐的机制，根目录的磁盘达到100%，pod被驱逐，且无法再正常创建在该节点。</p>
<p>解决方案如下：</p>
<p>1、关闭kubelet的驱逐机制。</p>
<p>2、清除根目录的文件，恢复根目录空间，并后续增加根目录的磁盘监控。</p>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-4a6e864a3e311d3029ea0182a946f368">3 - 镜像拉取失败问题</h1>
    
	<p>常见镜像拉取问题排查</p>
<h2 id="1-pod状态为errimagepull或imagepullbackoff">1. Pod状态为ErrImagePull或ImagePullBackOff</h2>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>docker-hub-75d4dfb984-5hggg           0/1     ImagePullBackOff   <span style="color:#0000cf;font-weight:bold">0</span>          14m     192.168.1.30   &lt;node ip&gt;   
</span></span><span style="display:flex;"><span>docker-hub-75d4dfb984-9r57b           0/1     ErrImagePull       <span style="color:#0000cf;font-weight:bold">0</span>          53s     192.168.0.42   &lt;node ip&gt;   
</span></span></code></pre></div><ul>
<li>ErrImagePull：表示pod已经调度到node节点，kubelet调用docker去拉取镜像失败。</li>
<li>ImagePullBackOff：表示kubelet拉取镜像失败后，不断重试去拉取仍然失败。</li>
</ul>
<h2 id="2-查看pod的事件">2. 查看pod的事件</h2>
<p>通过kubectl describe pod 命令查看pod事件，该事件的报错信息在kubelet或docker的日志中也会查看到。</p>
<h3 id="2-1-http-server-gave-http-response-to-https-client">2.1. http: server gave HTTP response to HTTPS client</h3>
<p>如果遇到以下报错，尝试将该镜像仓库添加到docker可信任的镜像仓库配置中。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>Error getting v2 registry: Get https://docker.com:8080/v2/: http: server gave HTTP response to HTTPS client<span style="color:#4e9a06">&#34;
</span></span></span></code></pre></div><p>具体操作是修改/etc/docker/daemon.json的insecure-registries参数</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">#cat /etc/docker/daemon.json</span>
</span></span><span style="display:flex;"><span><span style="color:#ce5c00;font-weight:bold">{</span>
</span></span><span style="display:flex;"><span>	...
</span></span><span style="display:flex;"><span>  <span style="color:#4e9a06">&#34;insecure-registries&#34;</span>: <span style="color:#ce5c00;font-weight:bold">[</span>
</span></span><span style="display:flex;"><span>	...
</span></span><span style="display:flex;"><span>    <span style="color:#4e9a06">&#34;docker.com:8080&#34;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#ce5c00;font-weight:bold">]</span>,
</span></span><span style="display:flex;"><span>  ...
</span></span><span style="display:flex;"><span><span style="color:#ce5c00;font-weight:bold">}</span>
</span></span></code></pre></div><h3 id="2-2-no-basic-auth-credentials">2.2. no basic auth credentials</h3>
<p>如果遇到<code>no basic auth credentials</code>报错，说明kubelet调用docker接口去拉取镜像时，镜像仓库的认证信息失败。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>  Normal   BackOff    18s               kubelet, 192.168.1.1  Back-off pulling image <span style="color:#4e9a06">&#34;docker.com:8080/public/2048:latest&#34;</span>
</span></span><span style="display:flex;"><span>  Warning  Failed     18s               kubelet, 192.168.1.1  Error: ImagePullBackOff
</span></span><span style="display:flex;"><span>  Normal   Pulling    5s <span style="color:#ce5c00;font-weight:bold">(</span>x2 over 18s<span style="color:#ce5c00;font-weight:bold">)</span>  kubelet, 192.168.1.1  Pulling image <span style="color:#4e9a06">&#34;docker.com:8080/public/2048:latest&#34;</span>
</span></span><span style="display:flex;"><span>  Warning  Failed     5s <span style="color:#ce5c00;font-weight:bold">(</span>x2 over 18s<span style="color:#ce5c00;font-weight:bold">)</span>  kubelet, 192.168.1.1  Failed to pull image <span style="color:#4e9a06">&#34;docker.com:8080/public/2048:latest&#34;</span>: rpc error: <span style="color:#000">code</span> <span style="color:#ce5c00;font-weight:bold">=</span> Unknown <span style="color:#000">desc</span> <span style="color:#ce5c00;font-weight:bold">=</span> Error response from daemon: Get http://docker.com:8080/v2/public/2048/manifests/latest: no basic auth credentials
</span></span><span style="display:flex;"><span>  Warning  Failed     5s <span style="color:#ce5c00;font-weight:bold">(</span>x2 over 18s<span style="color:#ce5c00;font-weight:bold">)</span>  kubelet, 192.168.1.1  Error: ErrImagePull
</span></span></code></pre></div><p>具体操作，在拉取镜像失败的节点上登录该镜像仓库，认证信息会更新到<code> $HOME/.docker/config.json</code>文件中。将该文件拷贝到<code>/var/lib/kubelet/config.json</code>中。</p>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-f2cc121604cda28beccb98599cfa50cc">4 - PVC Terminating</h1>
    
	<h1 id="问题描述">问题描述</h1>
<pre tabindex="0"><code>pvc terminating
</code></pre><p>pvc在删除时，卡在terminating中。</p>
<h1 id="解决方法">解决方法</h1>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl patch pvc <span style="color:#ce5c00;font-weight:bold">{</span>PVC_NAME<span style="color:#ce5c00;font-weight:bold">}</span> -p <span style="color:#4e9a06">&#39;{&#34;metadata&#34;:{&#34;finalizers&#34;:null}}&#39;</span>
</span></span></code></pre></div>
</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-1fc63b5dc9513028d22327de8b197dcf">5 - ConfigMap多行格式</h1>
    
	<h2 id="问题">问题</h2>
<p>configmap出现多行文本无法正常显示换行格式，而是以<code>\n</code>连接文本，查看和编辑时可读性很差。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">apiVersion</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">v1</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline"></span><span style="color:#204a87;font-weight:bold">data</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">  </span><span style="color:#204a87;font-weight:bold">config.yaml</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#4e9a06">&#34;# log options\nlog_level: \&#34;info\&#34;\nlog_output: \&#34;stderr\&#34;\ncert_file:
</span></span></span><span style="display:flex;"><span><span style="color:#4e9a06">    \&#34;/etc/webhook/certs/cert.pem\&#34;\nkey_file: \&#34;/etc/webhook/certs/key.pem\&#34;\nhttp_listen:
</span></span></span><span style="display:flex;"><span><span style="color:#4e9a06">    \&#34;:8080\&#34;\nhttps_listen: \&#34;:8443\&#34;\ningress_publish_service: \nenable_profiling:
</span></span></span><span style="display:flex;"><span><span style="color:#4e9a06">    true\nkubernetes:\n  kubeconfig: \&#34;\&#34;\n  resync_interval: \&#34;6h\&#34;\n  app_namespaces:\n
</span></span></span><span style="display:flex;"><span><span style="color:#4e9a06">    \ - \&#34;*\&#34;\n  namespace_selector:\n  - \&#34;\&#34;\n  election_id: \&#34;ingress-apisix-leader\&#34;\n
</span></span></span><span style="display:flex;"><span><span style="color:#4e9a06">    \ ingress_class: \&#34;ph-apisix\&#34;\n  ingress_version: \&#34;networking/v1\&#34;\n  watch_endpointslices:
</span></span></span><span style="display:flex;"><span><span style="color:#4e9a06">    false\n  apisix_route_version: \&#34;apisix.apache.org/v2beta3\&#34;\n  enable_gateway_api:
</span></span></span><span style="display:flex;"><span><span style="color:#4e9a06">    false\napisix:\n  default_cluster_base_url: http://apisix-admin.apisix.svc.cluster.local:9180/apisix/admin\n
</span></span></span><span style="display:flex;"><span><span style="color:#4e9a06">    \ default_cluster_admin_key: \&#34;edd1c9f034335f136f87ad84b625c8f1\&#34;\n  default_cluster_name:
</span></span></span><span style="display:flex;"><span><span style="color:#4e9a06">    \&#34;default\&#34;&#34;</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline"></span><span style="color:#204a87;font-weight:bold">kind</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">ConfigMap</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span></code></pre></div><h2 id="解决方案">解决方案</h2>
<p>如果要保持多行输入和输出的格式，则需要符合以下情况：</p>
<ul>
<li>文本不要以空格结尾</li>
<li>不要换行前再带个空格</li>
<li>不要在文本中添加不可见特殊字符</li>
</ul>
<p>将文本拷贝并格式化yaml文本。可使用在线格式化工具：<a href="https://verytoolz.com/yaml-formatter.html">YAML在线格式化</a>。</p>
<p>将格式化的文本拷贝到configmap文件，并检查上述三个问题。一般是因以<code>空格结尾</code>导致，搜索空格并去除行末的空格。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">apiVersion</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">v1</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline"></span><span style="color:#204a87;font-weight:bold">data</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">  </span><span style="color:#204a87;font-weight:bold">config.yaml</span><span style="color:#000;font-weight:bold">:</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000;font-weight:bold">|-</span><span style="color:#8f5902;font-style:italic">
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">    # log options
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">    log_level: &#34;info&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">    log_output: &#34;stderr&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">    cert_file: &#34;/etc/webhook/certs/cert.pem&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">    key_file: &#34;/etc/webhook/certs/key.pem&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">    http_listen: &#34;:8080&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">    https_listen: &#34;:8443&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">    ingress_publish_service:
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">    enable_profiling: true</span><span style="color:#f8f8f8;text-decoration:underline">    
</span></span></span></code></pre></div><p>参考：</p>
<ul>
<li><a href="https://kennylong.io/fix-yaml-multi-line-format/">https://kennylong.io/fix-yaml-multi-line-format/</a></li>
</ul>

</div>



    
	
  



          </main>
        </div>
      </div>
      
<footer class="bg-dark py-5 row d-print-none">
  <div class="container-fluid mx-sm-5">
    <div class="row">
      <div class="col-6 col-sm-4 text-xs-center order-sm-2">
        
        
        
      </div>
      <div class="col-6 col-sm-4 text-right text-xs-center order-sm-3">
        
        
        
<ul class="list-inline mb-0">
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="GitHub" aria-label="GitHub">
    <a class="text-white" target="_blank" rel="noopener" href="https://github.com/huweihuang/blog.huweihuang.com" aria-label="GitHub">
      <i class="fab fa-github"></i>
    </a>
  </li>
  
</ul>

        
        
      </div>
      <div class="col-12 col-sm-4 text-center py-2 order-sm-2">
        <small class="text-white">&copy; 2025 www.huweihuang.com 保留所有权利</small>
        <small class="ml-1"><a href="https://policies.google.com/privacy" target="_blank" rel="noopener">隐私政策</a></small>
	
		<p class="mt-2"><a href="/about/">About</a></p>
	
      </div>
    </div>
  </div>
</footer>


    </div>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js"
    integrity="sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN"
    crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js"
    integrity="sha512-UR25UO94eTnCVwjbXozyeVd6ZqpaAE9naiEUBK/A+QDbfSTQFhPGj5lOR6d8tsgbBk84Ggb5A3EkjsOgPRPcKA=="
    crossorigin="anonymous"></script>





<script src='/js/tabpane-persist.js'></script>




















<script src="/js/main.min.91798a335c881f1b6b805085ba4aa22d1dbd2b0b18d105d05189fa104ddae350.js" integrity="sha256-kXmKM1yIHxtrgFCFukqiLR29KwsY0QXQUYn6EE3a41A=" crossorigin="anonymous"></script>



<script src='/js/prism.js'></script>



  </body>
</html>
